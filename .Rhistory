eval(parse(text=txt))
}
}
# If there were any changes in the tool during data collection, they can be run here
source('src/sections/tool_modification.R')
# select the columns in your data that contain date elements
date_cols_main <- c("start","end", tool.survey %>% filter(type == "date" & datasheet == "main") %>% pull(name),
"submission_time") # add them here
# transform them into the datetime format
raw.main <- raw.main %>%
mutate_at(date_cols_main, ~ifelse(!str_detect(., '-'), as.character(convertToDateTime(as.numeric(.))), .))
rm(date_cols_main)
# specify the number of standard deviations you want to use
n.sd <- 3
# specify methods for  detecting outliers
method <- "o1"
# ignore 0 values or not
ignore_0 <- T
# specify columns for check or leave them empty
cols.integer_raw.main <- c()
cols.integer_raw.loop1 <- c()
cols.integer_raw.loop2 <- c()
cols.integer_raw.loop3 <- c()
source('src/sections/section_6_detect_and_visualise_outliers.R')
cleaning.log.outliers
wb <- createWorkbook()
addWorksheet(wb, 'Sheet 1')
writeDataTable(wb, sheet = 1, x = cleaning.log.outliers)
validate <- c("value corrected","value checked")
which(names(cleaning.log.outliers)=='checked')
names(cleaning.log.outliers)=='checked'
cleaning.log.outliers$checked <- NA
names(cleaning.log.outliers)=='checked'
which(names(cleaning.log.outliers)=='checked'), type = 'list', value = validate)
dataValidation(wb, 1, col = which(names(cleaning.log.outliers)=='checked'), type = 'list', value = validate)
help(dataValidation)
dataValidation(wb, 1, rows = 2:(nrow(cleaning.log.outliers)+1),
col = which(names(cleaning.log.outliers)=='checked'), type = 'list', value = validate)
validate
validate <- list("value corrected","value checked")
dataValidation(wb, 1, rows = 2:(nrow(cleaning.log.outliers)+1),
col = which(names(cleaning.log.outliers)=='checked'), type = 'list', value = validate)
wb <- createWorkbook()
addWorksheet(wb, 'Sheet 1')
writeDataTable(wb, sheet = 1, x = cleaning.log.outliers)
validate <- list("value corrected","value checked")
saveWorkbook(wb, 'dataValidationExample.xlsx', overwrite = T)
validate <- data.frame(values= c"value corrected","value checked"))
wb <- createWorkbook()
addWorksheet(wb, 'Sheet 1')
writeDataTable(wb, sheet = 1, x = cleaning.log.outliers)
validate <- data.frame(values= c("value corrected","value checked"))
writeData(wb, sheet = "Drop-down values", x = validate, startCol =
1)
addWorksheet(wb, 'Drop-down values')
writeData(wb, sheet = "Drop-down values", x = validate, startCol =
1)
wb <- createWorkbook()
addWorksheet(wb, 'Sheet 1')
addWorksheet(wb, 'Drop-down values')
validate <- data.frame(values= c("value corrected","value checked"))
writeData(wb, sheet = "Drop-down values", x = validate, startCol = 1)
writeDataTable(wb, sheet = 1, x = cleaning.log.outliers)
dataValidation(wb, 1, rows = 2:(nrow(cleaning.log.outliers)+1),
col = which(names(cleaning.log.outliers)=='checked'),
type = 'list', value = "'Drop-down values'!$A$2:$A$3")
saveWorkbook(wb, paste0("output/checking/outliers/outlier_analysis_", n.sd, "sd.xlsx"), overwrite=T, overwrite = T)
saveWorkbook(wb, paste0("output/checking/outliers/outlier_analysis_", n.sd, "sd.xlsx"), overwrite = T)
knitr::opts_chunk$set(echo = TRUE)
cleaning.log.outliers <- read.xlsx(paste0("output/checking/outliers/outlier_analysis_", n.sd, "sd.xlsx"),
sheet = 1)
cleaning.log.outliers <- cleaning.log.outliers %>% filter(checked%==%'value corrected')
make.filename.xlsx("output/Cleaning_logbook", "Cleaning_logbook")
knitr::opts_chunk$set(echo = TRUE)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
rm(list = ls())
directory_dictionary <- list(
research_cycle_name = 'xxxx',
round = 'xxxx',
dir.audits = "data/inputs/audits/reach/", # The directory to your audit files
dir.audits.check = "output/checking/audit/",# The directory to your audit summary files (you'll be checking these)
dir.requests = "output/checking/requests/", # the directory of your other_requests file
dir.responses = "output/checking/responses/", # the directory of your responses to open questions
enum_colname = "XXX", # the column that contains the enumerator ID,
enum_comments = 'XXX', # the column that contains the enumerator's comments,
filename.tool = "resources/MSNA_2023_Questionnaire_Final_CATI_cleaned.xlsx", # the name of your Kobo tool and its path
data_name = "XXXX.xlsx", # the name of your dataframe
data_path = "data/inputs/kobo_export/", # the path to your dataframe
label_colname = 'label::English', # the name of your label column. Has to be identical in Kobo survey and choices sheets
dctime_short = "XXXX" # the data of your survey (just for naming)
)
#-------------------------------Initialize packages, load tools -----------------------------
source("src/init.R")
# load a single raw Kobo data export:
# and loads the data into kobo.raw.main, kobo.raw.loop1...
# also included are the standard steps of renaming uuid, and adding the loop_index
raw_data_filename <- list.files(directory_dictionary$data_path, full.names = T)
if(length(raw_data_filename) > 1) { stop("Found multiple files containing raw Kobo data! Please clean up the kobo_export folder.")
}else if(length(raw_data_filename) == 0){
warning("Raw Kobo data not found!")
kobo.raw.main <- data.frame()
kobo.raw.loop1 <- data.frame()
dataset_creation_time <- NA
dctime_short <- ""
}else if(length(raw_data_filename) == 1){
ls <- excel_sheets(path = raw_data_filename)
sheet_names <- if(length(ls)>1){
c('kobo.raw.main',paste0('kobo.raw.loop',1:(length(ls)-1)))
}else{
'kobo.raw.main'
}
for(i in 1:length(ls)){
if(i==1){
kobo.raw.main <- readxl::read_xlsx(raw_data_filename, col_types = "text", sheet = ls[i])
}else{
txt <- paste0(sheet_names[i],'=readxl::read_xlsx(raw_data_filename, col_types = "text", sheet = "',ls[i],'")%>%
mutate(loop_index = paste0("loop',i-1,'_", loop_index))'
)
eval(parse(text = txt))
}
}
dataset_creation_time <- as.Date(file.info(raw_data_filename)$ctime)
dctime_short <- str_extract(gsub('-', '', str_sub(dataset_creation_time, 3)), "\\d+")
}
rm(raw_data_filename)
source('src/sections/process_old_data.R')
# final preparation
# Rename your dataframes
raw.main <- kobo.raw.main
sheet_names <- sheet_names[sheet_names!='kobo.raw.main']
sheet_names_new <- gsub('kobo.','',sheet_names)
if(length(sheet_names_new)>0){
for(i in 1:length(sheet_names_new)){
txt <- paste0(sheet_names_new[i],' <- ',sheet_names[i])
eval(parse(text=txt))
}
}
# If there were any changes in the tool during data collection, they can be run here
source('src/sections/tool_modification.R')
# select the columns in your data that contain date elements
date_cols_main <- c("start","end", tool.survey %>% filter(type == "date" & datasheet == "main") %>% pull(name),
"submission_time") # add them here
# transform them into the datetime format
raw.main <- raw.main %>%
mutate_at(date_cols_main, ~ifelse(!str_detect(., '-'), as.character(convertToDateTime(as.numeric(.))), .))
# name that hosts the clean recode.others file, leave as '' if you don't have this file. Nothing will be recoded that way
name_clean_others_file <- 'UKR2308_MSNA_other_response_230802'
cleaning.log <- data.frame()
or.edited  <- utilityR::load.requests(directory_dictionary$dir.requests,
name_clean_others_file,
sheet = sheet_name_others, validate = T)
sheet_name_others <- 'Sheet2' # name of the sheet where you're holding your requests
or.edited  <- utilityR::load.requests(directory_dictionary$dir.requests,
name_clean_others_file,
sheet = sheet_name_others, validate = T)
names_req <- or.edited %>%
pull(name,ref.name)
names_list <- names(raw.main)
if(length(sheet_names_new)>0){
for(frame in sheet_names_new){
txt <- paste0("names(",frame,")")
names_loop <- eval(parse(text=txt))
names_list <- c(names_list,names_loop)
}
}
names_missing <- setdiff(names_req,names_list)
if(length(names_missing)>0){
stop((paste0("some of the names in your tool are not present in your dataframe. Please double check if they were renamed: ",
paste0(names_missing,collapse = ',\n'))))
}
# check if all of `None type answers are used`
none_selection = c('do_not_know','prefer_not_to_answer','none','none_of_the_above',
'dont_know','do_not_want_to_answer')
none_check <- or.edited %>%
dplyr::filter(!is.na(existing.v)) %>%
dplyr::mutate(existing2=tolower(gsub('[[:punct:]]','',existing.v))) %>%
dplyr::rowwise() %>%
dplyr::mutate(similarity =max(stringdist::stringsim(existing2,gsub('_',' ',none_selection),
method = 'jaccard',q=1))) %>%
dplyr::filter(similarity>0.8)
if(nrow(none_check)>0){
warning(paste0(
"It seems some of the values in the existing.v column are to be recoded to `None`,`Don't know`,'Prefer not to answer',etc.
Values please make sure that their choice names are present in the `none_selection` object.
We have found the following cases: ",
paste0('uuid: ',none_check$uuid,
'ref.column: ',none_check$ref.name,
'value:', none_check$existing.v,collapse=";"),
'\nIf you recoded more `None` cases then we found, please make sure that their choice names are also present in the `none_selection` object'))
}
warning(paste0(
"It seems some of the values in the existing.v column are to be recoded to `None`,`Don't know`,'Prefer not to answer',etc.
Values please make sure that their choice names are present in the `none_selection` object.
We have found the following cases: ",
paste0('uuid: ',none_check$uuid,
'ref.column: ',none_check$ref.name,
'value:', none_check$existing.v,collapse=";\n"),
'\nIf you recoded more `None` cases then we found, please make sure that their choice names are also present in the `none_selection` object'))
warning(paste0(
"It seems some of the values in the existing.v column are to be recoded to `None`,`Don't know`,'Prefer not to answer',etc.
Values please make sure that their choice names are present in the `none_selection` object.
We have found the following cases: ",
paste0('uuid: ',none_check$uuid,
' ref.column: ',none_check$ref.name,
' value:', none_check$existing.v,collapse=";\n"),
'\nIf you recoded more `None` cases then we found, please make sure that their choice names are also present in the `none_selection` object'))
warning(paste0(
"It seems some of the values in the existing.v column are to be recoded to `None`,`Don't know`,'Prefer not to answer',etc.
Values please make sure that their choice names are present in the `none_selection` object.
We have found the following cases: ",
paste0('uuid: ',none_check$uuid,
' ref.column: ',none_check$ref.name,
' value: ', none_check$existing.v,collapse=";\n"),
'\nIf you recoded more `None` cases then we found, please make sure that their choice names are also present in the `none_selection` object'))
# separate the other translations to fit each individual dataframe that you have - no unnecessary variables in each
raw.main_requests <- or.edited %>%
filter(name %in% names(raw.main))
if(exists('raw.loop1')){
raw.loop1_requests <- or.edited %>%
filter(name %in% names(raw.loop1))
if(nrow(raw.loop1_requests)==0){
rm(raw.loop1_requests)
}
}
if(exists('raw.loop2')){
raw.loop2_requests <- or.edited %>%
filter(name %in% names(raw.loop2))
if(nrow(raw.loop2_requests)==0){
rm(raw.loop2_requests)
}
}
if(exists('raw.loop3')){
raw.loop3_requests <- or.edited %>%
filter(name %in% names(raw.loop3))
if(nrow(raw.loop3_requests)==0){
rm(raw.loop3_requests)
}
}
# If you face any weird double spaces
tool.choices$`label::English`=str_squish(tool.choices$`label::English`)
tool.choices$name=str_squish(tool.choices$name)
# Create a cleaning log file for each loop if there's a need for it.
cleaning.log.other.main <- utilityR::recode.others(
data = raw.main,
or.edited = raw.main_requests,
orig_response_col = 'response.uk',
is.loop = F,
tool.choices = tool.choices,
tool.survey = tool.survey,
none_selection = none_selection)
detach("package:utilityR", unload = TRUE)
remove.packages("utilityR")
devtools::install_github('https://github.com/Nestor-Ch/utilityR')
help(recode.others)
??recode.others
‘??recode.others’
library(utilityR)
help("recode.others")
# Create a cleaning log file for each loop if there's a need for it.
cleaning.log.other.main <- utilityR::recode.others(
data = raw.main,
or.edited = raw.main_requests,
orig_response_col = 'response.uk',
is.loop = F,
tool.choices = tool.choices,
tool.survey = tool.survey,
none_selection = none_selection)
View(cleaning.log.other.main)
View(none_check)
names_missing
names_tool <- tool.survey %>%
filter(grepl('(select_one)|(select_multiple)|(integer)|(decimal)',type)) %>% pull(name)
names_list <- names(raw.main)
if(length(sheet_names_new)>0){
for(frame in sheet_names_new){
txt <- paste0("names(",frame,")")
names_loop <- eval(parse(text=txt))
names_list <- c(names_list,names_loop)
}
}
names_missing
if(length(names_missing)>0){
stop((paste0("some of the names in your tool are not present in your dataframe. Please double check if they were renamed: ",
paste0(names_missing,collapse = ',\n'))))
}
names_tool <- tool.survey %>%
filter(grepl('(select_one)|(select_multiple)|(integer)|(decimal)',type)) %>% pull(name)
names_list <- names(raw.main)
if(length(sheet_names_new)>0){
for(frame in sheet_names_new){
txt <- paste0("names(",frame,")")
names_loop <- eval(parse(text=txt))
names_list <- c(names_list,names_loop)
}
}
sheet_names_new
names_list
knitr::opts_chunk$set(echo = TRUE)
raw.main <- kobo.raw.main
sheet_names <- sheet_names[sheet_names!='kobo.raw.main']
sheet_names_new <- gsub('kobo.','',sheet_names)
if(length(sheet_names_new)>0){
for(i in 1:length(sheet_names_new)){
txt <- paste0(sheet_names_new[i],' <- ',sheet_names[i])
eval(parse(text=txt))
}
}
names_tool <- tool.survey %>%
filter(grepl('(select_one)|(select_multiple)|(integer)|(decimal)',type)) %>% pull(name)
names_tool <- tool.survey %>%
dplyr::filter(grepl('(select_one)|(select_multiple)|(integer)|(decimal)',type)) %>% dplyr::pull(name)
names_list <- names(raw.main)
if(length(sheet_names_new)>0){
for(frame in sheet_names_new){
txt <- paste0("names(",frame,")")
names_loop <- eval(parse(text=txt))
names_list <- c(names_list,names_loop)
}
}
names_missing <- setdiff(names_tool,names_list)
names_missing
# select the columns in your data that contain date elements
date_cols_main <- c("start","end", tool.survey %>% filter(type == "date" & datasheet == "main") %>% pull(name),
"submission_time") # add them here
# transform them into the datetime format
raw.main <- raw.main %>%
mutate_at(date_cols_main, ~ifelse(!str_detect(., '-'), as.character(convertToDateTime(as.numeric(.))), .))
knitr::opts_chunk$set(echo = TRUE)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
rm(list = ls())
directory_dictionary <- list(
research_cycle_name = 'xxxx',
round = 'xxxx',
dir.audits = "data/inputs/audits/reach/", # The directory to your audit files
dir.audits.check = "output/checking/audit/",# The directory to your audit summary files (you'll be checking these)
dir.requests = "output/checking/requests/", # the directory of your other_requests file
dir.responses = "output/checking/responses/", # the directory of your responses to open questions
enum_colname = "XXX", # the column that contains the enumerator ID,
enum_comments = 'XXX', # the column that contains the enumerator's comments,
filename.tool = "resources/MSNA_2023_Questionnaire_Final_CATI_cleaned.xlsx", # the name of your Kobo tool and its path
data_name = "XXXX.xlsx", # the name of your dataframe
data_path = "data/inputs/kobo_export/", # the path to your dataframe
label_colname = 'label::English', # the name of your label column. Has to be identical in Kobo survey and choices sheets
dctime_short = "XXXX" # the data of your survey (just for naming)
)
#-------------------------------Initialize packages, load tools -----------------------------
source("src/init.R")
# load a single raw Kobo data export:
# and loads the data into kobo.raw.main, kobo.raw.loop1...
# also included are the standard steps of renaming uuid, and adding the loop_index
raw_data_filename <- list.files(directory_dictionary$data_path, full.names = T)
if(length(raw_data_filename) > 1) { stop("Found multiple files containing raw Kobo data! Please clean up the kobo_export folder.")
}else if(length(raw_data_filename) == 0){
warning("Raw Kobo data not found!")
kobo.raw.main <- data.frame()
kobo.raw.loop1 <- data.frame()
dataset_creation_time <- NA
dctime_short <- ""
}else if(length(raw_data_filename) == 1){
ls <- excel_sheets(path = raw_data_filename)
sheet_names <- if(length(ls)>1){
c('kobo.raw.main',paste0('kobo.raw.loop',1:(length(ls)-1)))
}else{
'kobo.raw.main'
}
for(i in 1:length(ls)){
if(i==1){
kobo.raw.main <- readxl::read_xlsx(raw_data_filename, col_types = "text", sheet = ls[i])
}else{
txt <- paste0(sheet_names[i],'=readxl::read_xlsx(raw_data_filename, col_types = "text", sheet = "',ls[i],'")%>%
mutate(loop_index = paste0("loop',i-1,'_", loop_index))'
)
eval(parse(text = txt))
}
}
dataset_creation_time <- as.Date(file.info(raw_data_filename)$ctime)
dctime_short <- str_extract(gsub('-', '', str_sub(dataset_creation_time, 3)), "\\d+")
}
rm(raw_data_filename)
source('src/sections/process_old_data.R')
# final preparation
# Rename your dataframes
raw.main <- kobo.raw.main
sheet_names <- sheet_names[sheet_names!='kobo.raw.main']
sheet_names_new <- gsub('kobo.','',sheet_names)
if(length(sheet_names_new)>0){
for(i in 1:length(sheet_names_new)){
txt <- paste0(sheet_names_new[i],' <- ',sheet_names[i])
eval(parse(text=txt))
}
}
# select the columns in your data that contain date elements
date_cols_main <- c("start","end", tool.survey %>% filter(type == "date" & datasheet == "main") %>% pull(name),
"submission_time") # add them here
# transform them into the datetime format
raw.main <- raw.main %>%
mutate_at(date_cols_main, ~ifelse(!str_detect(., '-'), as.character(convertToDateTime(as.numeric(.))), .))
rm(date_cols_main)
# If there were any changes in the tool during data collection, they can be run here
source('src/sections/tool_modification.R')
# name that hosts the clean recode.others file, leave as '' if you don't have this file. Nothing will be recoded that way
name_clean_others_file <- 'UKR2308_MSNA_other_response_230802'
sheet_name_others <- 'Sheet2' # name of the sheet where you're holding your requests
or.edited  <- utilityR::load.requests(directory_dictionary$dir.requests,
name_clean_others_file,
sheet = sheet_name_others, validate = T)
View(or.edited)
or.edited <- or.edited[1:1000,]
raw.main %>% filter(uuid=='59eaa74f-06b2-4ede-ac73-dbdedf74b3ac') %>% pull(D_3_living_conditions_issues)
raw.main %>% filter(uuid=='10f47014-1d44-430a-b78a-416def351603') %>% pull(D_3_living_conditions_issues)
raw.main %>% filter(uuid=='b873963f-6ed0-461f-8e82-52cf4795f4f1') %>% pull(D_3_living_conditions_issues)
raw.main %>% filter(uuid=='3b63117b-3eb0-47a7-8d75-6fc863537592') %>% pull(D_9_missing_nfi)
raw.main %>% filter(uuid=='2e2181a3-84db-4ea3-ac1e-ee78f7c7b46d') %>% pull(D_9_missing_nfi)
raw.main %>% filter(uuid==or.edited[or.edited$existing.v=='None',]$uuid) %>% pull(D_9_missing_nfi)
raw.main %>% filter(uuid%in%or.edited[or.edited$existing.v=='None',]$uuid) %>% pull(D_9_missing_nfi)
raw.main %>% filter(uuid %in% or.edited[or.edited$existing.v=='None',]$uuid) %>% pull(D_9_missing_nfi)
raw.main %>% filter(uuid %in% or.edited[or.edited$existing.v=='None',]$uuid)
uuid %in% or.edited[or.edited$existing.v=='None',]$uuid
uuid %in% or.edited[or.edited$existing.v%in%'None',]$uuid
or.edited[or.edited$existing.v%in%'None',]$uuid
or.edited[or.edited$existing.v%in%'None of the above;',]$uuid
raw.main %>% filter(uuid %in% or.edited[or.edited$existing.v=='None of the above;',]$uuid)
raw.main %>% filter(uuid %in% or.edited[or.edited$existing.v=='None of the above;',]$uuid) %>% pull('D_9_missing_nfi_other')
raw.main %>% filter(uuid %in% or.edited[or.edited$existing.v=='None of the above;',]$uuid) %>% pull('D_9_missing_nfi')
raw.main %>% filter(uuid %in% 'b87fdd53-f775-4e71-ab0a-d81f370dc7fd') %>% pull('D_9_missing_nfi')
names_req <- or.edited %>%
pull(name,ref.name)
names_list <- names(raw.main)
if(length(sheet_names_new)>0){
for(frame in sheet_names_new){
txt <- paste0("names(",frame,")")
names_loop <- eval(parse(text=txt))
names_list <- c(names_list,names_loop)
}
}
names_missing <- setdiff(names_req,names_list)
if(length(names_missing)>0){
stop((paste0("some of the names in your tool are not present in your dataframe. Please double check if they were renamed: ",
paste0(names_missing,collapse = ',\n'))))
}
# check if all of `None type answers are used`
none_selection = c('do_not_know','prefer_not_to_answer','none','none_of_the_above',
'dont_know','do_not_want_to_answer')
none_check <- or.edited %>%
dplyr::filter(!is.na(existing.v)) %>%
dplyr::mutate(existing2=tolower(gsub('[[:punct:]]','',existing.v))) %>%
dplyr::rowwise() %>%
dplyr::mutate(similarity =max(stringdist::stringsim(existing2,gsub('_',' ',none_selection),
method = 'jaccard',q=1))) %>%
dplyr::filter(similarity>0.8)
if(nrow(none_check)>0){
warning(paste0(
"It seems some of the values in the existing.v column are to be recoded to `None`,`Don't know`,'Prefer not to answer',etc.
Values please make sure that their choice names are present in the `none_selection` object.
We have found the following cases: ",
paste0('uuid: ',none_check$uuid,
' ref.column: ',none_check$ref.name,
' value: ', none_check$existing.v,collapse=";\n"),
'\nIf you recoded more `None` cases then we found, please make sure that their choice names are also present in the `none_selection` object'))
}
# separate the other translations to fit each individual dataframe that you have - no unnecessary variables in each
raw.main_requests <- or.edited %>%
filter(name %in% names(raw.main))
View(raw.main_requests)
View(none_check)
# If you face any weird double spaces
tool.choices$`label::English`=str_squish(tool.choices$`label::English`)
tool.choices$name=str_squish(tool.choices$name)
# Create a cleaning log file for each loop if there's a need for it.
cleaning.log.other.main <- utilityR::recode.others(
data = raw.main,
or.edited = raw.main_requests,
orig_response_col = 'response.uk',
is.loop = F,
tool.choices = tool.choices,
tool.survey = tool.survey,
none_selection = none_selection)
View(cleaning.log.other.main)
# specify the number of standard deviations you want to use
n.sd <- 3
# specify methods for  detecting outliers
method <- "o1"
# ignore 0 values or not
ignore_0 <- T
# specify as many loops as you need
# specify columns for check or leave them empty
cols.integer_raw.main <- c()
cols.integer_raw.loop1 <- c()
cols.integer_raw.loop2 <- c()
cols.integer_raw.loop3 <- c()
source('src/sections/section_6_detect_and_visualise_outliers.R')
# check if all of `None type answers are used`
none_selection = c('do_not_know','prefer_not_to_answer','none','none_of_the_above',
'dont_know','do_not_want_to_answer')
none_check <- or.edited %>%
dplyr::filter(!is.na(existing.v)) %>%
dplyr::mutate(existing2=tolower(gsub('[[:punct:]]','',existing.v))) %>%
dplyr::rowwise() %>%
dplyr::mutate(similarity =max(stringdist::stringsim(existing2,gsub('_',' ',none_selection),
method = 'jaccard',q=1))) %>%
dplyr::filter(similarity>0.8)
View(none_check)
if(nrow(none_check)>0){
warning(paste0(
"It seems some of the values in the existing.v column are to be recoded to `None`,`Don't know`,'Prefer not to answer',etc.
Values please make sure that their choice names are present in the `none_selection` object.
We have found the following cases: ",
paste0('uuid: ',none_check$uuid,
' ref.column: ',none_check$ref.name,
' value: ', none_check$existing.v,collapse=";\n"),
'\nIf you recoded more `None` cases then we found, please make sure that their choice names are also present in the `none_selection` object'))
}
