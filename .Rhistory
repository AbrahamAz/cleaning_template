ls()[grepl('^raw,',ls())]
ls()[grepl('^raw.',ls())]
ls()[grepl('^raw.main$',ls())]
ls()[grepl('^raw.main$|^raw.loop.',ls())]
ls()[grepl('^raw.main$|^raw.loop',ls())]
ls()[grepl('^raw.main$|^raw.loop{d}',ls())]
ls()[grepl('^raw.main$|^raw.loop[:digit"]',ls())]
ls()[grepl('^raw.main$|^raw.loop[:digit:]',ls())]
ls()[grepl('^raw.main$|^raw.loop[[:digit:]]',ls())]
ls()[grepl('^raw.main$|^raw.loop[[:digit:]]$',ls())]
ls()[grepl('^raw.loop[[:digit:]]$|^raw.main$',ls())]
data.list <- ls()[grepl('^raw.loop[[:digit:]]$|^raw.main$',ls())]
sheets
ls
ls[2:length(ls)]
if(length(ls)>1){
ls_loops <- ls[2:length(ls)]
}
if(length(ls)>1){
ls_loops <- ls[2:length(ls)]
}else{ls_loops <- c()}
c()
ls_loops
paste0('"',ls_loops,'" = ',data.list)
paste0('"',ls_loops,'" = ',data.list, collapse = ',')
ls_loops
data.list
data.list <- ls()[grepl('^raw.loop[[:digit:]]$',ls())]
data.list
paste0(
'list = ("main" =raw.main,',
paste0('"',ls_loops,'" = ',data.list, collapse = ','),')'
)
paste0(
'datasheets <-list = ("main" =raw.main,',
paste0('"',ls_loops,'" = ',data.list, collapse = ','),')'
)
eval(parse(text= txt))
datasheets
txt <- paste0(
'datasheets <-list = ("main" =raw.main,',
paste0('"',ls_loops,'" = ',data.list, collapse = ','),')'
)
eval(parse(text= txt))
paste0(
'datasheets <-list = ("main" =raw.main,',
paste0('"',ls_loops,'" = ',data.list, collapse = ','),')'
)
txt <- paste0(
'datasheets <-list("main" =raw.main,',
paste0('"',ls_loops,'" = ',data.list, collapse = ','),')'
)
eval(parse(text= txt))
data.list <- ls()[grepl('^kobo.raw.loop[[:digit:]]$',ls())]
data.list
ls_loops
pii.to.remove_main <- c(
"deviceid",
"staff_other",
"audit",
"audit_URL",
"username")
raw.main  <- raw.main %>% select(-any_of(pii.to.remove_main))
if(length(ls)>1){
ls_loops <- ls[2:length(ls)]
}else{ls_loops <- c()}
data.list <- ls()[grepl('^kobo.raw.loop[[:digit:]]$',ls())]
txt <- paste0(
'datasheets <-list("main" =kobo.raw.main,',
paste0('"',ls_loops,'" = ',data.list, collapse = ','),')'
)
eval(parse(text= txt))
write.xlsx(datasheets, make.filename.xlsx("output/data_log", "full_data"), overwrite = T,
zoom = 90, firstRow = T)
data.list <- ls()[grepl('^raw.loop[[:digit:]]$',ls())]
txt <- paste0(
'datasheets_anon <-list("main" =raw.main,',
paste0('"',ls_loops,'" = ',data.list, collapse = ','),')'
)
eval(parse(text= txt))
write.xlsx(datasheets_anon, make.filename.xlsx("output/final", "final_anonymized_data"), overwrite = T,
zoom = 90, firstRow = T)
setdiff(names(raw.main),names(kobo.raw.main))
sheet_names[i]
gsub('kobo','',sheet_names)
sheet_names_new <- gsub('kobo.','',sheet_names)
sheet_names_new[sheet_names_new!='raw.main']
sheet_names_new <- sheet_names_new[sheet_names_new!='raw.main']
sheet_names_new[i]
i=1
sheet_names_new[i]
sheet_names
sheet_names <- sheet_names[sheet_names!='kobo.raw.main']
sheet_names_new <- gsub('kobo.','',sheet_names)
sheet_names_new
sheet_names
paste0(sheet_names_new[i],'=',sheet_names[i])
if(length(sheet_names_new)>0){
for(i in 1:length(sheet_names_new)){
txt <- paste0(sheet_names_new[i],'=',sheet_names[i])
eval(parse(txt))
}
}
i
txt
if(length(sheet_names_new)>0){
for(i in 1:length(sheet_names_new)){
txt <- paste0(sheet_names_new[i],' <- ',sheet_names[i])
eval(parse(txt))
}
}
txt
if(length(sheet_names_new)>0){
for(i in 1:length(sheet_names_new)){
txt <- paste0(sheet_names_new[i],' <- ',sheet_names[i])
eval(parse(text=txt))
}
}
source("src/load_Data.R")
setdiff(names(raw.main),names(kobo.raw.main))
names(kobo.raw.main)
pii.to.remove_main <- c(
"deviceid",
"staff_other",
"audit",
"audit_URL",
"username")
raw.main  <- raw.main %>% select(-any_of(pii.to.remove_main))
setdiff(names(raw.main),names(kobo.raw.main))
names(kobo.raw.main)
raw.main %>% select(-any_of(pii.to.remove_main))
setdiff(names(raw.main),names(kobo.raw.main))
setdiff(names(kobo.raw.main),names(raw.main))
deleted_colums <- data.frame(variable=setdiff(names(kobo.raw.main),names(raw.main)),
action = 'removed',
rationale = NA
)
deleted_colums
data_extract <- raw.main[,c('uuid', directory_dictionary$enum_colname)]
data_extract
cleaning.log %>%
left_join(kobo.raw.main %>% select(uuid,deviceid ))
cleaning.log
tibble(cleaning.log)
logbook <- cleaning.log %>%
left_join(kobo.raw.main %>% select(uuid,deviceid )) %>%
mutate(type_of_issue = NA,
changed = 'Yes',
feedback=NA) %>%
select(uuid, enumerator_id,deviceid,variable,issue, type_of_issue,feedback,changed,old.value, new.value)
logbook
logbook <- cleaning.log %>%
left_join(kobo.raw.main %>% select(uuid,deviceid )) %>%
mutate(type_of_issue = NA,
changed = 'Yes',
feedback=NA) %>%
select(uuid, enumerator_id,deviceid,variable,issue, type_of_issue,feedback,changed,old.value, new.value) %>%
tibble()
logbook
deletion.log.new
deletion.log.audits
deletion.log.new <- bind_rows(deletion.log.new, deletion.log.audits)
deletion.log.new
directory_dictionary
deletion.log.new %>%
left_join(kobo.raw.main %>% select(uuid,deviceid,all_of(directory_dictionary$enum_colname) ))
deletion.log.new
deletion.log.new %>%
left_join(raw.main %>% select(uuid,deviceid,all_of(directory_dictionary$enum_colname) ))
deletion.log.new %>%
left_join(kobo.raw.main %>% select(uuid,deviceid,all_of(directory_dictionary$enum_colname) )) %>%
distinct()
make.filename.xlsx("output/enum_performance.", "Enumerator_performance_temp")
source("src/load_Data.R")
deleted_colums <- data.frame(variable=setdiff(names(kobo.raw.main),names(raw.main)),
action = 'removed',
rationale = NA
)
data_extract <- raw.main[,c('uuid', directory_dictionary$enum_colname)]
logbook <- cleaning.log %>%
left_join(kobo.raw.main %>% select(uuid,deviceid )) %>%
mutate(type_of_issue = NA,
changed = 'Yes',
feedback=NA) %>%
select(uuid, enumerator_id,deviceid,variable,issue, type_of_issue,feedback,changed,old.value, new.value) %>%
tibble()
del_log <- deletion.log.new %>%
left_join(kobo.raw.main %>% select(uuid,deviceid,all_of(directory_dictionary$enum_colname) )) %>%
distinct() %>%
select(uuid,all_of(directory_dictionary$enum_colname),deviceid,reason) %>%
mutate(type_of_issue = NA,
feedback = 'deleted')
submission_file <- list(
'variable_tracker' =deleted_colums,
'data_extract'=data_extract,
'logbook' = logbook,
'del_log'=del_log
)
write.xlsx(submission_file, make.filename.xlsx("output/enum_performance.", "Enumerator_performance_temp"), overwrite = T,
zoom = 90, firstRow = T)
write.xlsx(submission_file, make.filename.xlsx("output", "Enumerator_performance_temp"), overwrite = T,
zoom = 90, firstRow = T)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
rm(list = ls())
directory_dictionary <- list(
dir.audits = "data/inputs/audits/reach/", # The directory to your audit files
dir.audits.check = "output/checking/audit/",# The directory to your audit summary files (you'll be checking these)
dir.requests = "output/checking/requests/", # the directory of your other_requests file
dir.responses = "output/checking/responses/", # the directory of your responses to open questions
enum_colname = "enumerator_id", # the column that contains the enumerator ID,
enum_comments = 'enum_comms', # the column that contains the enumerator's comments,
filename.tool = "resources/Reach_UKR2306_CCCM_DS_tool_r2_v3 1.xlsx", # the name of your Kobo tool and its path
data_name = "Reach_UKR2306_CCCM_DS_tool_r2_-_all_versions_-_False_-_2023-11-25-09-58-22 (1).xlsx", # the name of your dataframe
data_path = "data/inputs/kobo_export/", # the path to your dataframe
label_colname = 'label::English', # the name of your label column. Has to be identical in Kobo survey and choices sheets
dctime_short = "2023_01_01" # the data of your survey (just for naming)
)
api_key <- source('resources/microsoft.api.key_regional.R')$value
#-------------------------------Initialize packages, load tools -----------------------------
source("src/init.R")
source("src/load_Data.R")
raw.main <- kobo.raw.main
sheet_names <- sheet_names[sheet_names!='kobo.raw.main']
sheet_names_new <- gsub('kobo.','',sheet_names)
if(length(sheet_names_new)>0){
for(i in 1:length(sheet_names_new)){
txt <- paste0(sheet_names_new[i],' <- ',sheet_names[i])
eval(parse(text=txt))
}
}
# If there were any changes in the tool during data collection, they can be run here
source('src/sections/tool_modification.R')
# select the columns in your data that contain date elements
date_cols_main <- c("start","end", tool.survey %>% filter(type == "date" & datasheet == "main") %>% pull(name),
"submission_time") # add them here
# transform them into the datetime format
raw.main <- raw.main %>%
mutate_at(date_cols_main, ~ifelse(!str_detect(., '-'), as.character(convertToDateTime(as.numeric(.))), .))
rm(date_cols_main)
#check for duplicates
ids <- raw.main$uuid[duplicated(raw.main$uuid)]
if (length(ids)>0) {
warning("Duplicate uuids detected: ", length(ids))
# add to deletion log
deletion.log.new <- utilityR::create.deletion.log(raw.main %>% filter(uuid %in% ids),
directory_dictionary$enum_colname, "Duplicate") # a brand new deletion log
} else{
deletion.log.new <- data.frame()
}
# check for duplicates in loop1
if(exists('raw.loop1')){
ids <- raw.loop1$loop_index[duplicated(raw.loop1$loop_index)]
if (length(ids)>0){
warning("Duplicate uuids detected: ", length(ids))
# add to deletion log
deletion.log.loop1 <- utilityR::create.deletion.log(raw.loop1 %>%
filter(loop_index %in% ids),directory_dictionary$enum_colname, "Duplicate",
is.loop = T,
data.main = raw.main) # a brand new deletion log
deletion.log.new <- bind_rows(deletion.log.new,deletion.log.loop1)
}
}
# check for duplicates in loop2
if(exists('raw.loop2')){
ids <- raw.loop2$loop_index[duplicated(raw.loop2$loop_index)]
if (length(ids)>0){
warning("Duplicate uuids detected: ", length(ids))
# add to deletion log
deletion.log.loop2 <- utilityR::create.deletion.log(raw.loop2 %>%
filter(loop_index %in% ids),
directory_dictionary$enum_colname,
"Duplicate",
is.loop = T,
data.main = raw.main) # a brand new deletion log
deletion.log.new <- bind_rows(deletion.log.new,deletion.log.loop2)
}
}
sheet_names_new
length(sheet_names_new)>0
sheet_names_new
paste0(loop,'$loop_index[duplicated(',loop,'$loop_index)]')
loop = "raw.loop1"
paste0(loop,'$loop_index[duplicated(',loop,'$loop_index)]')
txt <- paste0(loop,'$loop_index[duplicated(',loop,'$loop_index)]')
eval(parse(text = txt))
paste0(loop,' %>% filter(loop_index %in% ids)')
txt <- paste0(loop,' %>% filter(loop_index %in% ids)')
dupl_df<- eval(parse(text = txt))
dupl_df
if(length(sheet_names_new)>0){
for(loop in sheet_names_new)
txt <- paste0(loop,'$loop_index[duplicated(',loop,'$loop_index)]')
ids <- eval(parse(text = txt))
if (length(ids)>0){
warning("Duplicate uuids detected: ", length(ids))
txt <- paste0(loop,' %>% filter(loop_index %in% ids)')
dupl_df<- eval(parse(text = txt))
# add to deletion log
deletion.log.loop <- utilityR::create.deletion.log(dupl_df,
directory_dictionary$enum_colname, "Duplicate",
is.loop = T,
data.main = raw.main) # a brand new deletion log
deletion.log.new <- bind_rows(deletion.log.new,deletion.log.loop)
}
}
deletion.log.loop
deletion.log.new
sheet_names_new
paste0(loop,'<-',loop,'[!(',loop,'$uuid %in% deletion.log.new$uuid),]')
source('src/sections/section_1_remove_duplicates_no_consents.R')
loop
txt
# --------------------------------Section  2  - Audit checks + soft duplicates -----------------------------------
min_duration_interview <- 5 # minimum duration of an interview (screen time in minutes)
max_duration_interview <- 60 # maximum duration of an interview (screen time in minutes)
pre_process_audit_files <- F # whether cases of respondent taking too long to answer 1 question should cleaned.
max_length_answer_1_question <- 20 # if pre_process_audit_files =T, enter the maximum time that
# the respondent can spend answering 1 question (in minutes)
min_num_diff_questions <- 12 # Used during the check for soft duplicates.
# the respondent can spend answering 1 question (in minutes)
min_num_diff_questions <- 8 # Used during the check for soft duplicates.
paste0(loop,'<-',loop,'[!(',loop,'$uuid %in% deletion.log.new$uuid),]')
sheet_names_new
sheet_names_new[[i]]
paste0('int_cols_loop',i,' <- tool.survey %>%
filter(type == "integer" & datasheet != "main" & name %in% names(',sheet_names_new[[i]],')) %>%
pull(name)')
paste0('cl_log_999_loop',i,' <- utilityR::recode.set.NA.if(raw.loop1,int_cols_loop1, code = code_for_check,issue = "Wrong entry")')
paste0(' bind_rows(cl_log_999,cl_log_999_loop',i,')')
paste0(
'datasheets <-list("main" =kobo.raw.main,',
paste0('"',ls_loops,'" = ',data.list, collapse = ','),')'
)
ls
apply(raw.main,2, function(x){
grepl('[\p{Cyrillic}]',x)
apply(raw.main,2, function(x){
grepl('[\\u0400-\\u04FF]',x)
})
names(raw.main)[-'uuid']
names(raw.main)
names(raw.main)[names(raw.main)!='uuid']
raw.main %>%
pivot_longer(cols= names(raw.main)[names(raw.main)!='uuid'], names_to = column, values_to = value)
raw.main %>%
pivot_longer(cols= names(raw.main)[names(raw.main)!='uuid'], names_to = 'column', values_to = 'value')
raw.main %>%
pivot_longer(cols= names(raw.main)[names(raw.main)!='uuid'], names_to = 'column', values_to = 'value') %>%
filter(grepl('[\\u0400-\\u04FF]',value))
raw.main %>%
pivot_longer(cols= names(raw.main)[names(raw.main)!='uuid'], names_to = 'column', values_to = 'value') %>%
filter(grepl('[а-я]',value))
raw.main %>%
pivot_longer(cols= names(raw.main)[names(raw.main)!='uuid'], names_to = 'column', values_to = 'value') %>%
filter(grepl('[а-яА-я]',value))
source('src/sections/section_4_apply_changes_to_requests.R')
name_clean_others_file <- 'DS_r2_other_requests_final_2023_12_04'
cleaning.log <- data.frame()
or.edited  <- utilityR::load.requests(directory_dictionary$dir.requests,
name_clean_others_file,
sheet = "Sheet2", validate = T)  # specify Sheet2 because the first one is a readme
if(any(or.edited$check == 1)){
issue <- paste0('uuid: ', or.edited[or.edited$check == 1,]$uuid,', variable: ',or.edited[or.edited$check == 1,]$name)
stop(paste0('Some of your entries have errors, please double-check: ', paste0(issue,collapse = '\n')))
}
or.edited <- or.edited[or.edited$check>1,]
# this is for the test purposes. You won't have to run it when you've worked through everything
or.edited <- or.edited %>%
filter(!(is.na(true.v)&is.na(existing.v) & is.na(invalid.v)))
# separate the other translations to fit each individual dataframe that you have - no unnecessary variables in each
raw.main_requests <- or.edited %>%
filter(name %in% names(raw.main))
if(exists('raw.loop1')){
raw.loop1_requests <- or.edited %>%
filter(name %in% names(raw.loop1))
if(nrow(raw.loop1_requests)==0){
rm(raw.loop1_requests)
}
}
if(exists('raw.loop2')){
raw.loop2_requests <- or.edited %>%
filter(name %in% names(raw.loop2))
if(nrow(raw.loop2_requests)==0){
rm(raw.loop2_requests)
}
}
if(exists('raw.loop3')){
raw.loop3_requests <- or.edited %>%
filter(name %in% names(raw.loop3))
if(nrow(raw.loop3_requests)==0){
rm(raw.loop3_requests)
}
}
if(!(nrow(raw.main_requests)+nrow(raw.loop1_requests)+nrow(raw.loop2_requests)+nrow(raw.loop3_requests)==nrow(or.edited))){
warning('The number of rows in each of the separated dataframes does not match the number of total rows. This may mean
that some of the variables in your edited file are not present in the dataframes')
all_names <- unique(c(
names(raw.main),names(raw.loop1),names(raw.loop2),names(raw.loop3)
))
print('Variables that may be causing this issue:')
print(setdiff(or.edited$name,all_names))
}
# If you face any weird double spaces
tool.choices$`label::English`=str_squish(tool.choices$`label::English`)
# Create a cleaning log file for each loop if there's a need for it.
cleaning.log.other.main <- utilityR::recode.others(data = raw.main,
or.edited = raw.main_requests,
orig_response_col = 'responses',
is.loop = F,
tool.choices = tool.choices,
tool.survey = tool.survey)
raw.main %>%
pivot_longer(cols= names(raw.main)[names(raw.main)!='uuid'], names_to = 'column', values_to = 'value') %>%
filter(grepl('[а-яА-я]',value))
if(exists('raw.loop1_requests')){
cleaning.log.other.loop1 <- utilityR::recode.others(data = raw.loop1,
or.edited = raw.loop1_requests,
orig_response_col = 'responses',
is.loop = T,
tool.choices = tool.choices,
tool.survey = tool.survey)
}else{cleaning.log.other.loop1 <- data.frame()}
raw.loop1_requests
raw.loop1
raw.loop1$loop_index
raw.loop1$loop_index
raw.loop3$loop_index
raw.loop2$loop_index
source("src/load_Data.R")
raw.loop2$loop_index
raw.main <- kobo.raw.main
sheet_names <- sheet_names[sheet_names!='kobo.raw.main']
sheet_names_new <- gsub('kobo.','',sheet_names)
if(length(sheet_names_new)>0){
for(i in 1:length(sheet_names_new)){
txt <- paste0(sheet_names_new[i],' <- ',sheet_names[i])
eval(parse(text=txt))
}
}
raw.loop2$loop_index
raw.loop1$loop_index
raw.loop3$loop_index
if(nrow(cleaning.log.other.loop1>0)){
raw.loop1 <- utilityR::apply.changes(raw.loop1,clog = cleaning.log.other.loop1,is.loop = T)
}
cleaning.log.other.main
# Create the cleaning log for recoding others
cleaning.log.other <- rbind(cleaning.log.other.main,cleaning.log.other.loop1,
cleaning.log.other.loop2,
cleaning.log.other.loop3
)
# bind it with the main cleaning log
cleaning.log <- bind_rows(cleaning.log, cleaning.log.other)
## Apply changes from the cleaning log onto our raw data
raw.main <- utilityR::apply.changes(raw.main, clog = cleaning.log.other.main,is.loop = F)
raw.main %>%
pivot_longer(cols= names(raw.main)[names(raw.main)!='uuid'], names_to = 'column', values_to = 'value') %>%
filter(grepl('[а-яА-я]',value))
raw.main %>%
pivot_longer(cols= names(raw.main)[names(raw.main)!='uuid'], names_to = 'column', values_to = 'value') %>%
filter(grepl('[а-яА-я]',value)) %>% pull(column) %>% unique
sheet_names_new
names(raw.main)[names(raw.main) `%not=%` vars_to_omit]
vars_to_omit <- c('uuid','loop_index')
raw.main %>%
pivot_longer(cols= names(raw.main)[names(raw.main) %not=% vars_to_omit], names_to = 'column', values_to = 'value') %>%
filter(grepl('[а-яА-я]',value))
raw.main %>%
pivot_longer(cols= names(raw.main)[!names(raw.main) %in% vars_to_omit], names_to = 'column', values_to = 'value') %>%
filter(grepl('[а-яА-я]',value))
paste0('cyrillic.',i,' <- ',i,' %>%
pivot_longer(cols= names(raw.main)[!names(raw.main) %in% vars_to_omit], names_to = 'variable', values_to = 'value') %>%
paste0('cyrillic.',i,' <- ',i,' %>%
pivot_longer(cols= names(raw.main)[!names(raw.main) %in% vars_to_omit], names_to = "variable", values_to = "value") %>%
filter(grepl("[а-яА-я]",value))')
sheet_names_new
sheet_names_new
i="raw.loop1"
paste0('cyrillic.',i,' <- ',i,' %>%
pivot_longer(cols= names(raw.main)[!names(raw.main) %in% vars_to_omit], names_to = "variable", values_to = "value") %>%
filter(grepl("[а-яА-я]",value))')
paste0('cyrillic.',i,' <- ',i,' %>%
pivot_longer(cols= names(',i,')[!names(',i,') %in% vars_to_omit], names_to = "variable", values_to = "value") %>%
filter(grepl("[а-яА-я]",value))')
help(get.select.db
)
aste0('if(nrow(cyrillic.',i,')>0')
paste0('if(nrow(cyrillic.',i,')>0')
paste0('if(nrow(cyrillic.',i,')>0){
warning("Your data sill has cyrillic entries, please check file cyrillic.',i,' for details")
}
')
cyrillic.main <- raw.main %>%
pivot_longer(cols= names(raw.main)[!names(raw.main) %in% vars_to_omit], names_to = 'variable', values_to = 'value') %>%
filter(grepl('[а-яА-я]',value))
if(nrow(cyrillic.main)>0){
warning('Your data sill has cyrillic entries, please check file cyrillic.main for details')
}
if(length(sheet_names_new)>0){
for(i in sheet_names_new){
txt <- paste0('cyrillic.',i,' <- ',i,' %>%
pivot_longer(cols= names(',i,')[!names(',i,') %in% vars_to_omit], names_to = "variable", values_to = "value") %>%
filter(grepl("[а-яА-я]",value))')
eval(parse(text=txt))
txt <- paste0('if(nrow(cyrillic.',i,')>0){
warning("Your data sill has cyrillic entries, please check file cyrillic.',i,' for details")
}')
eval(parse(text=txt))
}
}
source('src/sections/section_4_post_check_for_leftover_cyrillic.R')
View(cyrillic.raw.loop3)
