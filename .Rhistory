## Add any changes to the tool?
raw.main <- raw.main %>%
select(-any_of(cols_remove, vars = NULL))
tool.survey <- tool.survey %>%
mutate(datasheet = "main")
raw.main <- raw.main %>%
rename(submission_time = "_submission_time") %>%
rename_all(~sub("_geolocation","geolocation", .x))
cols_to_drop_main <- c(
tool.survey %>% filter(type == "note") %>% pull(name),      # all note columns
colnames(raw.main)[str_starts(colnames(raw.main), "_")]     # all columns with names starting with underscore
)
raw.main <- raw.main %>% select(-any_of(cols_to_drop_main, vars=NULL)) %>% relocate(uuid)
# fix dates:
date_cols_main <- c("date_survey","start","end", tool.survey %>% filter(type == "date" & datasheet == "main") %>% pull(name),
"submission_time")
raw.main <- raw.main %>%
mutate_at(date_cols_main, ~ifelse(!str_detect(., '-'), as.character(convertToDateTime(as.numeric(.))), .))
rm(cols_to_drop_main, date_cols_main)
# check for duplicates
ids <- raw.main$uuid[duplicated(raw.main$uuid)]
if (length(ids)>0) warning("Duplicate uuids detected: ", length(ids))
# add to deletion log
deletion.log.new <- create.deletion.log(raw.main %>% filter(uuid %in% ids),enum_colname, "Duplicate") # a brand new deletion log
rm(ids)
# check for no consent
no_consents <- raw.main %>% filter(a1_a_consent == "no")
if (nrow(no_consents) > 0) warning("No-consent detected: ", nrow(no_consents))
# add to deletion log
if("no_consent_reasons" %in% colnames(raw.main)){
deletion.log.no_consents <- no_consents %>%
mutate(reason = paste0("no consent", ifelse(is.na(no_consent_reasons), "", paste0(": ", no_consent_reasons)))) %>% select(uuid, !!sym(enum_colname), reason)
# translate the no-consents reasons :)
deletion.log.no_consents <- deletion.log.no_consents %>% translate.responses("reason") %>%
mutate(reason = str_to_lower(response.en.from.uk)) %>% select(-response.en.from.uk)
}else{
deletion.log.no_consents <- no_consents %>% create.deletion.log(enum_colname, "no consent")
}
deletion.log.new <- rbind(deletion.log.new, deletion.log.no_consents)
####################################################
## run this to remove duplicates and no-consents  ##
raw.main  <- raw.main[!(raw.main$uuid %in% deletion.log.new$uuid),]
rm(no_consents, deletion.log.no_consents)
audits <- load.audit.files(dir.audits, uuids = raw.main$uuid, track.changes = F)
View(audits)
process.uuid <- function(df){
# df <- audits
max.num.iterations <- 15
t <- list() # Time of each iteration
rt <- list() # response time of each iteration
j <- list() # number of jumps
q <- list() # number of questions
w <- list() # waiting time
e <- list() # number of edits
t1 <- df$start[1]
if (df$event[1]!="form.start") stop("First event is not form.start?!")
status <- "filling"
for (r in 2:nrow(df)){
if (status=="filling" & df$event[r]=="form.exit"){
t2 <- df$start[r]
t <- append(t, (t2-t1)/1000/60)
sub.df <- filter(df, start>=t1 & start<=t2)
questions <- filter(sub.df, event %in% c("question", "group.questions"))
rt <- append(rt, sum(questions$duration)/60)
q <- append(q, length(unique(questions$node)))
j <- append(j, sum(sub.df$event=="jump"))
e <- append(e, nrow(filter(questions, !is.na(`old.value`) & `old.value`!="")))
status <- "waiting"
} else if (status=="waiting" & df$event[r]=="form.resume"){
t1 <- df$start[r]
w <- append(w, (t1-t2)/1000/60)
status <- "filling"
} else if (status=="waiting" & df$event[r]=="form.exit"){
if("uuid2" %in% colnames(df)) warning(paste("status=waiting while form.exit! uuid:",df$uuid2[r]))
else warning("status=waiting while form.exit!")
}
}
res <- data.frame()
res[1, "n.iteration"] <- length(t)
res[1, "tot.t"] <- round((df[nrow(df), "start"] - df[1, "start"])/60000, 1)
res[1, "tot.rt"] <- round(sum(filter(df, event %in% c("question", "group.questions"))$duration)/60, 1)
for (i in 1:max.num.iterations){
res[1, c(paste0("t", i), paste0("rt", i),
paste0("q", i), paste0("j", i),
paste0("e", i),
paste0("w", i))] <- NA
}
if (length(t)==0) stop()
else{
for (i in 1:min(length(t), max.num.iterations)){
res[1, paste0("t", i)] <- round(t[[i]], 1)
res[1, paste0("rt", i)] <- round(rt[[i]], 1)
res[1, paste0("q", i)] <- q[[i]]
res[1, paste0("j", i)] <- j[[i]]
res[1, paste0("e", i)] <- e[[i]]
}
}
if (length(w)>0){
for (i in 1:min(length(w), max.num.iterations)) res[1, paste0("w", i)] <- round(w[[i]], 1)
}
if("uuid2" %in% colnames(res)) res <- res %>% select(-uuid2)
# new functionality :)
# res <- res %>%  discard(~any_of(is.na(.)))  # dropping empty columns (all NA)
return(res)
}
audi <- audits
audits.summary <- audi %>%
group_by(uuid) %>%
group_modify(~process.uuid(.x))
audi <- audits %>%
filter(uuid %in% c("00356cbb-ca60-4404-890b-5e460777fa1b","0a93cab0-d9de-45ba-949a-a56fb3663bfc"))
audits.summary <- audi %>%
group_by(uuid) %>%
group_modify(~process.uuid(.x))
View(audits.summary)
audi <- audits %>%
filter(uuid %in% c("0a93cab0-d9de-45ba-949a-a56fb3663bfc"))
audits.summary <- audi %>%
group_by(uuid) %>%
group_modify(~process.uuid(.x))
View(audits)
audi <- audits %>%
filter(uuid %in% c("00356cbb-ca60-4404-890b-5e460777fa1b","00802536-a749-49e3-9987-0d6936360b22"))
audits.summary <- audi %>%
group_by(uuid) %>%
group_modify(~process.uuid(.x))
View(audits.summary)
audits.summary <- audits %>%
group_by(uuid) %>%
group_modify(~process.uuid(.x)) #### TO DEBUGGGGGG
View(audits.summary)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
rm(list = ls())
####################
##  LOAD Tool     ##
####################
source("src/init.R")
source("src/load_Data.R")
# small utility functions
make.short.name <- function(name, no_date = F) return(gsub("__","_", paste0("HSM_", name, ifelse(no_date, "", paste0("_", dctime_short)))))
make.filename.xlsx <- function(dir = ".", name, no_date = F) return(gsub("//","/", paste0(dir, "/", make.short.name(name, no_date), ".xlsx")))
# ########################################
# ##  load & remove previous data        ##
# raw.main <- kobo.raw.main %>%          ##
#   filter(!(uuid %in% uuids_to_remove))
# raw.loop1 <- kobo.raw.loop1 %>%        ##
#   filter(!(uuid %in% uuids_to_remove))
# # raw.loop2 <- kobo.raw.loop2 %>%        ##
# #   filter(!(uuid %in% uuids_to_remove))
#                                        ##
########################################
raw.main <- kobo.raw.main
# Change in the tool
cols_remove <- c(
"d6_sanitation/none_of_the_above",
"g2_vulnerable_IDP/none_of_the_above"
)
## Add any changes to the tool?
raw.main <- raw.main %>%
select(-any_of(cols_remove, vars = NULL))
tool.survey <- tool.survey %>%
mutate(datasheet = "main")
raw.main <- raw.main %>%
rename(submission_time = "_submission_time") %>%
rename_all(~sub("_geolocation","geolocation", .x))
cols_to_drop_main <- c(
tool.survey %>% filter(type == "note") %>% pull(name),      # all note columns
colnames(raw.main)[str_starts(colnames(raw.main), "_")]     # all columns with names starting with underscore
)
raw.main <- raw.main %>% select(-any_of(cols_to_drop_main, vars=NULL)) %>% relocate(uuid)
# fix dates:
date_cols_main <- c("date_survey","start","end", tool.survey %>% filter(type == "date" & datasheet == "main") %>% pull(name),
"submission_time")
raw.main <- raw.main %>%
mutate_at(date_cols_main, ~ifelse(!str_detect(., '-'), as.character(convertToDateTime(as.numeric(.))), .))
rm(cols_to_drop_main, date_cols_main)
# check for duplicates
ids <- raw.main$uuid[duplicated(raw.main$uuid)]
if (length(ids)>0) warning("Duplicate uuids detected: ", length(ids))
# add to deletion log
deletion.log.new <- create.deletion.log(raw.main %>% filter(uuid %in% ids),enum_colname, "Duplicate") # a brand new deletion log
rm(ids)
# check for no consent
no_consents <- raw.main %>% filter(a1_a_consent == "no")
if (nrow(no_consents) > 0) warning("No-consent detected: ", nrow(no_consents))
# add to deletion log
if("no_consent_reasons" %in% colnames(raw.main)){
deletion.log.no_consents <- no_consents %>%
mutate(reason = paste0("no consent", ifelse(is.na(no_consent_reasons), "", paste0(": ", no_consent_reasons)))) %>% select(uuid, !!sym(enum_colname), reason)
# translate the no-consents reasons :)
deletion.log.no_consents <- deletion.log.no_consents %>% translate.responses("reason") %>%
mutate(reason = str_to_lower(response.en.from.uk)) %>% select(-response.en.from.uk)
}else{
deletion.log.no_consents <- no_consents %>% create.deletion.log(enum_colname, "no consent")
}
deletion.log.new <- rbind(deletion.log.new, deletion.log.no_consents)
####################################################
## run this to remove duplicates and no-consents  ##
raw.main  <- raw.main[!(raw.main$uuid %in% deletion.log.new$uuid),]
rm(no_consents, deletion.log.no_consents)
audits <- load.audit.files(dir.audits, uuids = raw.main$uuid, track.changes = F)
View(process.uuid)
if(nrow(audits) == 0) {audits.summary <- tibble(uuid = raw.main$uuid, tot.rt = NA)
}else{
audits.summary <- audits %>%
group_by(uuid) %>%
group_modify(~process.uuid(.x)) #### TO DEBUGGGGGG
}
strings <- c(
dataset.name = "IDP Collective Site Monitoring Round 6",      # provide a full name for the title of output documents (e.g. "[POL] Post-Distribution Monitoring")
dataset.name.short = "IDP CSM R6",   # provide a short name for filenames of output documents (e.g. "POL_PDM")
dataset.date = "December 2022",       # this string is only used for creating titles for output documents
out_date = stringr::str_sub(stringr::str_remove_all(Sys.Date(), '-'), 3),      # this one is appended to the end of filenames
filename.data = "data/data.xlsx",      # the filename of your data for analysis
filename.tool = "resources/tool.xlsx",      # filename of your kobo tool
filename.daf.tabular = "resources/???.xlsx"  ,    # filename of your DAF
)
strings <- c(
dataset.name = "IDP Collective Site Monitoring Round 6",      # provide a full name for the title of output documents (e.g. "[POL] Post-Distribution Monitoring")
dataset.name.short = "IDP CSM R6",   # provide a short name for filenames of output documents (e.g. "POL_PDM")
dataset.date = "December 2022",       # this string is only used for creating titles for output documents
out_date = stringr::str_sub(stringr::str_remove_all(Sys.Date(), '-'), 3),      # this one is appended to the end of filenames
filename.data = "data/data.xlsx",      # the filename of your data for analysis
filename.tool = "resources/tool.xlsx",      # filename of your kobo tool
filename.daf.tabular = "resources/???.xlsx"     # filename of your DAF
)
strings <- c(
dataset.name = "IDP Collective Site Monitoring Round 6",      # provide a full name for the title of output documents (e.g. "[POL] Post-Distribution Monitoring")
dataset.name.short = "IDP CSM R6",   # provide a short name for filenames of output documents (e.g. "POL_PDM")
dataset.date = "December 2022",       # this string is only used for creating titles for output documents
out_date = stringr::str_sub(stringr::str_remove_all(Sys.Date(), '-'), 3),      # this one is appended to the end of filenames
filename.data = "data/data.xlsx",      # the filename of your data for analysis
filename.tool = "resources/tool.xlsx",      # filename of your kobo tool
filename.daf.tabular = "resources/DAF_csm.xlsx"     # filename of your DAF
)
params  <- c(
fix_sheet_names_to_match = "data",     # this should be one of "tool", "data", or "none"
combine_folder = "temp/combine/"
)
rm(list=ls()[!ls() %in% c("params", "strings")])
source("src/init.R")
source("src/init.R")
View(daf)
View(data.list)
data.list$main$strata %>% unique
source("src/fix_bugged_names.R")
source("src/format_dataset.R")  # <- additional indicators and grouping variables are added here
data.list$main <- data.list$main %>%
mutate(overall = "overall",
weight = 1
)
# all additional columns from data that need to be included in srvyr designs (need to be present in all sheets):
special_vars <- c("overall", "weight", daf$admin) %>% unique
## FINAL TOUCHUPS TO DAF, CONVERTING COLUMNS
################################################################################
## a lookup tibble for variable/column names:
var_lookup <- tibble()
for (sheet in names(data.list)){
var_lookup <- rbind(var_lookup, tibble(variable = names(data.list[[sheet]]), datasheet = sheet)) %>%
distinct(variable, .keep_all = T) %>% filter(str_detect(variable, "(/)|(___)", T))
# ^ here, I am assuming that no one will put a variable in the DAF that contains '/' or '___', or starts with '_'
# also note that by using distinct here, if the same variable appears in multiple sheets, then by default the first sheet will be used (so: main usually)
}
# ADD DATASHEET COLUMN TO DAF
if(!"datasheet" %in% names(daf)) daf <- daf %>% left_join(var_lookup, by = "variable")
missing_sheets <- daf %>% filter(is.na(datasheet)) %>% pull(variable)
if(length(missing_sheets) > 0) stop("These variables are missing from data: ", paste(missing_sheets))
rm(missing_sheets)
# CONVERT!
source("src/convert_cols_with_daf.R")
## SRVYR DESIGNS
##############################################################################
srvyr.designs  <- list()
for(sheet in names(data.list)){
daf_vars <- daf %>% filter(var_type != "select_multiple" & datasheet == sheet) %>% pull(variable)
daf_vars_sm <- daf %>% filter(var_type == "select_multiple" & datasheet == sheet) %>% pull(variable)
sm_vars_pattern <- paste0("^",paste0("(",daf_vars_sm,")", collapse = "|"))
daf_disaggs <- daf %>% filter(!isna(disaggregations) & datasheet == sheet) %>% pull(disaggregations) %>% str_split(" *; *") %>% unlist %>% unique
daf_disaggs <- daf_disaggs[daf_disaggs!=""]
survey_data <- data.list[[sheet]] %>% select(all_of(special_vars), all_of(daf_vars), all_of(daf_disaggs), matches(sm_vars_pattern))
srvyr.designs[[sheet]] <- as_survey_design(survey_data, weights = NULL)
rm(survey_data, daf_vars, daf_vars_sm, daf_disaggs)
}
sections <- daf %>% select(section) %>% distinct() %>% pull()
i <- "IDP"
add_to_html.section(i)
daf.section <- daf %>% filter(section == i)
View(daf.section)
r <- 6
# read entry from analysis flan
entry <- load_entry(daf.section[r,])
View(entry)
add_to_html.title(entry)
cat(paste0("\n\nVariable name: <em><strong>", entry$variable),"</strong></em>")
cat(entry$comments)
# get the appropriate data source:
srvyr.design <- srvyr.designs[[entry$datasheet]]
# filter out NAs
if(entry$omit_na) srvyr.design <- srvyr.design %>% filter(!is.na(!!sym(entry$variable)))
# check if any data for this variable is left at all:
if(nrow(srvyr.design) == 0) {
cat("\n\nNo data for this variable (all NA).\n")
next
}else{
if(!entry$omit_na){
cat(paste("\n\nIncluding NA values.\n"))
}else{
cat(paste("&emsp;|&emsp;",as_perc((nrow(srvyr.design))/nrow(data.list[[entry$datasheet]])),"of respondents answered this question.\n"))
}
}
# group by admin:
srvyr.design <- srvyr.design %>% group_by(!!sym(entry$admin))
View(entry)
disagg.var <- NA
res <- make_table(srvyr.design, entry, disagg.var) %>% ungroup %>% select(-any_of("overall"))
res <- make_table(srvyr.design, entry, disagg.var)
View(srvyr.designs)
View(srvyr.design)
View(entry)
# grouping - if no disaggregations, then simply by admin
# (the design is already grouped by admin, so another group_by will not do anything)
if(isna(disagg.var)) disagg.var <- entry$admin
srvyr.design.grouped <- srvyr.design %>% group_by(!!sym(disagg.var), .add = T)
# select the relevant columns / variables
srvyr.design.grouped <- switch (entry$func,
select_multiple = { srvyr.design.grouped %>% select(starts_with(entry$variable) & contains("___")) },
# default - just select the relevant variable:
{ srvyr.design.grouped %>% select(!!sym(entry$variable)) }
)
# calculate metrics
res <- switch (entry$func,
numeric =    { srvyr.design.grouped %>%
summarise(
num_samples = n(),
mean  =  survey_mean(  !!sym(entry$variable), na.rm = T, vartype = "var"),
median = survey_median(!!sym(entry$variable), na.rm = T, vartype = "var"),
min = min(!!sym(entry$variable), na.rm = T),
max = max(!!sym(entry$variable), na.rm = T)) },
select_one = { srvyr.design.grouped  %>%
make_table.select_one(entry, add_total = entry$add_total & disagg.var != entry$admin) },
select_multiple = { srvyr.design.grouped %>%
make_table.select_multiple(entry, add_total = entry$add_total & disagg.var != entry$admin) }
)
rlang::last_error()
strings <- c(
dataset.name = "IDP Collective Site Monitoring Round 6",      # provide a full name for the title of output documents (e.g. "[POL] Post-Distribution Monitoring")
dataset.name.short = "IDP CSM R6",   # provide a short name for filenames of output documents (e.g. "POL_PDM")
dataset.date = "December 2022",       # this string is only used for creating titles for output documents
out_date = stringr::str_sub(stringr::str_remove_all(Sys.Date(), '-'), 3),      # this one is appended to the end of filenames
filename.data = "data/data.xlsx",      # the filename of your data for analysis
filename.tool = "resources/tool.xlsx",      # filename of your kobo tool
filename.daf.tabular = "resources/DAF_csm.xlsx"     # filename of your DAF
)
params  <- c(
fix_sheet_names_to_match = "data",     # this should be one of "tool", "data", or "none"
combine_folder = "temp/combine/"
)
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE)
options(scipen = 999)
rm(list=ls()[!ls() %in% c("params", "strings")])
source("src/init.R")
rm(list=ls()[!ls() %in% c("params", "strings")])
source("src/init.R")
source("src/init.R")
rm(list=ls()[!ls() %in% c("params", "strings")])
source("src/init.R")
source("src/fix_bugged_names.R")
source("src/format_dataset.R")  # <- additional indicators and grouping variables are added here
data.list$main <- data.list$main %>%
mutate(overall = "overall",
weight = 1
)
# all additional columns from data that need to be included in srvyr designs (need to be present in all sheets):
special_vars <- c("overall", "weight", daf$admin) %>% unique
## FINAL TOUCHUPS TO DAF, CONVERTING COLUMNS
################################################################################
## a lookup tibble for variable/column names:
var_lookup <- tibble()
for (sheet in names(data.list)){
var_lookup <- rbind(var_lookup, tibble(variable = names(data.list[[sheet]]), datasheet = sheet)) %>%
distinct(variable, .keep_all = T) %>% filter(str_detect(variable, "(/)|(___)", T))
# ^ here, I am assuming that no one will put a variable in the DAF that contains '/' or '___', or starts with '_'
# also note that by using distinct here, if the same variable appears in multiple sheets, then by default the first sheet will be used (so: main usually)
}
# ADD DATASHEET COLUMN TO DAF
if(!"datasheet" %in% names(daf)) daf <- daf %>% left_join(var_lookup, by = "variable")
missing_sheets <- daf %>% filter(is.na(datasheet)) %>% pull(variable)
if(length(missing_sheets) > 0) stop("These variables are missing from data: ", paste(missing_sheets))
rm(missing_sheets)
# CONVERT!
source("src/convert_cols_with_daf.R")
## SRVYR DESIGNS
##############################################################################
srvyr.designs  <- list()
for(sheet in names(data.list)){
daf_vars <- daf %>% filter(var_type != "select_multiple" & datasheet == sheet) %>% pull(variable)
daf_vars_sm <- daf %>% filter(var_type == "select_multiple" & datasheet == sheet) %>% pull(variable)
sm_vars_pattern <- paste0("^",paste0("(",daf_vars_sm,")", collapse = "|"))
daf_disaggs <- daf %>% filter(!isna(disaggregations) & datasheet == sheet) %>% pull(disaggregations) %>% str_split(" *; *") %>% unlist %>% unique
daf_disaggs <- daf_disaggs[daf_disaggs!=""]
survey_data <- data.list[[sheet]] %>% select(all_of(special_vars), all_of(daf_vars), all_of(daf_disaggs), matches(sm_vars_pattern))
srvyr.designs[[sheet]] <- as_survey_design(survey_data, weights = NULL)
rm(survey_data, daf_vars, daf_vars_sm, daf_disaggs)
}
sections <- daf %>% select(section) %>% distinct() %>% pull()
i <- "abraham"
add_to_html.section(i)
daf.section <- daf %>% filter(section == i)
r <- 1
# read entry from analysis flan
entry <- load_entry(daf.section[r,])
add_to_html.title(entry)
cat(paste0("\n\nVariable name: <em><strong>", entry$variable),"</strong></em>")
cat(entry$comments)
# get the appropriate data source:
srvyr.design <- srvyr.designs[[entry$datasheet]]
# filter out NAs
if(entry$omit_na) srvyr.design <- srvyr.design %>% filter(!is.na(!!sym(entry$variable)))
# check if any data for this variable is left at all:
if(nrow(srvyr.design) == 0) {
cat("\n\nNo data for this variable (all NA).\n")
next
}else{
if(!entry$omit_na){
cat(paste("\n\nIncluding NA values.\n"))
}else{
cat(paste("&emsp;|&emsp;",as_perc((nrow(srvyr.design))/nrow(data.list[[entry$datasheet]])),"of respondents answered this question.\n"))
}
}
# group by admin:
srvyr.design <- srvyr.design %>% group_by(!!sym(entry$admin))
# loop through each disagg.var
for (disagg.var in entry$disaggregate.variables) {
if(!isna(disagg.var)) cat("\nDisaggregated by:<em><strong>", paste0(disagg.var),"</strong></em>")
res <- make_table(srvyr.design, entry, disagg.var) %>% ungroup %>% select(-any_of("overall"))
# add overall
if(entry$admin != "overall"){
entry.ovrl <- entry
entry.ovrl$admin <- "overall"
if(!"overall" %in% (srvyr.design %>% variable.names)) srvyr.design <- srvyr.design %>% mutate(overall = "overall")
res.overall <- make_table(srvyr.design %>% ungroup %>% group_by(overall),
entry.ovrl, disagg.var)  %>%
mutate(!!sym(entry$admin) := "overall") %>%
ungroup %>% select(-any_of("overall"))
res <- res %>% bind_rows(res.overall) %>% distinct
}
# save the xlsx
xlsx_name <- paste0(entry$xlsx_name, ifelse(isna(disagg.var), "", paste0("_by_", disagg.var)))
write_xlsx(res, paste0(params["combine_folder"],"/",xlsx_name,".xlsx"))
subch(datatable(res, option = tableFormat))
}
# grouping - if no disaggregations, then simply by admin
# (the design is already grouped by admin, so another group_by will not do anything)
if(isna(disagg.var)) disagg.var <- entry$admin
srvyr.design.grouped <- srvyr.design %>% group_by(!!sym(disagg.var), .add = T)
# select the relevant columns / variables
srvyr.design.grouped <- switch (entry$func,
select_multiple = { srvyr.design.grouped %>% select(starts_with(entry$variable) & contains("___")) },
# default - just select the relevant variable:
{ srvyr.design.grouped %>% select(!!sym(entry$variable)) }
)
# calculate metrics
res <- switch (entry$func,
numeric =    { srvyr.design.grouped %>%
summarise(
num_samples = n(),
mean  =  survey_mean(  !!sym(entry$variable), na.rm = T, vartype = "var"),
median = survey_median(!!sym(entry$variable), na.rm = T, vartype = "var"),
min = min(!!sym(entry$variable), na.rm = T),
max = max(!!sym(entry$variable), na.rm = T)) },
select_one = { srvyr.design.grouped  %>%
make_table.select_one(entry, add_total = entry$add_total & disagg.var != entry$admin) },
select_multiple = { srvyr.design.grouped %>%
make_table.select_multiple(entry, add_total = entry$add_total & disagg.var != entry$admin) }
)
View(make_table)
# calculate metrics
res <- srvyr.design.grouped %>%
make_table.select_multiple(entry, add_total = entry$add_total & disagg.var != entry$admin) }
# calculate metrics
res <- srvyr.design.grouped %>%
make_table.select_multiple(entry, add_total = entry$add_total & disagg.var != entry$admin)
disagg_vars <- c(entry$admin, entry$disaggregate.variables)
if(any(isna(disagg_vars))) disagg_vars <- NULL
disagg_vars <- disagg_vars[disagg_vars %in% (srvyr.design.grouped %>% variable.names)]
# calculate the totals and percentages, then join them together
s_props <- srvyr.design.grouped %>%
summarise(across(.fns = list(prop = ~ survey_mean(., na.rm = T, vartype = "var"))))
View(s_props)
s_samples <- srvyr.design.grouped %>%
summarise(num_samples = survey_total(na.rm = T, vartype = "var"))
View(s_samples)
res <- s_samples %>% left_join(s_props, by = disagg_vars)
View(res)
# convert choice names to labels (all except the NA column)
res <- res %>% rename_with(~get.choice.label(sm_ccols_to_choices(.), entry$list_name, simplify = T),
ends_with("_prop") & !contains("___NA"))
View(get.choice.label)
View(res)
cat(paste0("Always ma,e sure to change the name of your output files in the function make.short.name in place of the ???"))
cat(paste0("Always make sure to change the name of your output files in the function make.short.name in place of the ???"))
## Section below only for research cycles that requires cleaning on regular basis and use one kobo server.
cat(paste0("Section below only for research cycles that requires cleaning on regular basis and use one kobo server."))
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
rm(list = ls())
####################
##  LOAD Tool     ##
####################
source("src/init.R")
# ------------------------------------------------------------------------------
# AFTER RECEIVING FILLED-OUT OTHER requests:
warning("#### Please remove if you have loops")
